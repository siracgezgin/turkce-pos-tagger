# TÃ¼rkÃ§e iÃ§in Ä°leri DÃ¼zey Ã‡ok KatmanlÄ± Hibrit Part-of-Speech (POS) Tagging Sistemi

<div align="center">

![GitHub language count](https://img.shields.io/github/languages/count/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=github&logoColor=white)
![GitHub top language](https://img.shields.io/github/languages/top/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=python&logoColor=white)
![License](https://img.shields.io/github/license/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=opensourceinitiative&logoColor=white)
![GitHub last commit](https://img.shields.io/github/last-commit/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=git&logoColor=white)
![Python Version](https://img.shields.io/badge/python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white)
![Build Status](https://img.shields.io/badge/build-passing-brightgreen?style=for-the-badge&logo=github-actions&logoColor=white)
![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen?style=for-the-badge&logo=codecov&logoColor=white)

**Bursa Teknik Ãœniversitesi â€¢ Bilgisayar MÃ¼hendisliÄŸi BÃ¶lÃ¼mÃ¼**

*BLM0467 DoÄŸal Dil Ä°ÅŸlemeye GiriÅŸ â€¢ 2025 GÃ¼z DÃ¶nemi â€¢ Akademik DÃ¶nem Projesi*

---

[![Proje Sunumu](https://img.shields.io/badge/ğŸ“½ï¸_Proje_Sunumu-Ä°zle-red?style=for-the-badge)](https://example.com/presentation)
[![Akademik Makale](https://img.shields.io/badge/ğŸ“„_Akademik_Makale-Oku-blue?style=for-the-badge)](https://example.com/paper)
[![Demo](https://img.shields.io/badge/ğŸ¯_CanlÄ±_Demo-Dene-green?style=for-the-badge)](https://example.com/demo)
[![API DokÃ¼mantasyonu](https://img.shields.io/badge/ğŸ“š_API_Docs-KeÅŸfet-orange?style=for-the-badge)](https://example.com/docs)

</div>

---

## Ä°Ã§indekiler

- [Projeye Genel BakÄ±ÅŸ](#-projeye-genel-bakÄ±ÅŸ)
- [AraÅŸtÄ±rma Motivasyonu ve Bilimsel KatkÄ±lar](#-araÅŸtÄ±rma-motivasyonu-ve-bilimsel-katkÄ±lar)
- [Sistem Mimarisi ve Teknik Detaylar](#ï¸-sistem-mimarisi-ve-teknik-detaylar)
- [Ä°novatif YaklaÅŸÄ±mlar ve Algoritmalar](#-inovatif-yaklaÅŸÄ±mlar-ve-algoritmalar)
- [Kurulum ve Deployment](#-kurulum-ve-deployment)
- [Performans Analizi ve KarÅŸÄ±laÅŸtÄ±rmalar](#-performans-analizi-ve-karÅŸÄ±laÅŸtÄ±rmalar)
- [API ReferansÄ± ve KullanÄ±m Ã–rnekleri](#-api-referansÄ±-ve-kullanÄ±m-Ã¶rnekleri)
- [Deneysel SonuÃ§lar ve Ablasyon Ã‡alÄ±ÅŸmalarÄ±](#-deneysel-sonuÃ§lar-ve-ablasyon-Ã§alÄ±ÅŸmalarÄ±)
- [KatkÄ±da Bulunma ve GeliÅŸtirme](#-katkÄ±da-bulunma-ve-geliÅŸtirme)
- [Akademik Referanslar ve AtÄ±flar](#-akademik-referanslar-ve-atÄ±flar)
- [Lisans ve Ä°letiÅŸim](#-lisans-ve-iletiÅŸim)

---

## Projeye Genel BakÄ±ÅŸ

### Proje TanÄ±mÄ±

Bu Ã§alÄ±ÅŸma, **TÃ¼rkÃ§e'nin morfolojik zenginliÄŸi ve sÃ¶zdizimsel karmaÅŸÄ±klÄ±ÄŸÄ±ndan** kaynaklanan Part-of-Speech (POS) tagging zorluklarÄ±nÄ± ele alan, **akademik araÅŸtÄ±rma standardÄ±nda** geliÅŸtirilmiÅŸ bir hibrit sistemdir. Proje, geleneksel istatistiksel yÃ¶ntemler ile modern makine Ã¶ÄŸrenmesi tekniklerini birleÅŸtirerek, **TÃ¼rkÃ§e doÄŸal dil iÅŸleme** alanÄ±nda Ã¶zgÃ¼n bir katkÄ± sunmaktadÄ±r.

### Temel Hedefler

- **YÃ¼ksek DoÄŸruluk**: TÃ¼rkÃ§e metinlerde %96+ POS tagging doÄŸruluÄŸu
- **HesaplamalÄ± Verimlilik**: Transformer modellere gÃ¶re 10x daha hÄ±zlÄ± iÅŸlem
- **Bellek Optimizasyonu**: Minimal kaynak kullanÄ±mÄ± ile endÃ¼striyel uygulanabilirlik
- **GenelleÅŸtirme YeteneÄŸi**: FarklÄ± metin tÃ¼rlerinde tutarlÄ± performans
- **AÃ§Ä±k Kaynak KatkÄ±sÄ±**: TÃ¼rkÃ§e NLP toplulugu iÃ§in eriÅŸilebilir araÃ§lar

### Problem TanÄ±mÄ± ve Ã‡Ã¶zÃ¼m YaklaÅŸÄ±mÄ±

**TÃ¼rkÃ§e POS Tagging'in Temel ZorluklarÄ±:**

1. **Morfotaktik KarmaÅŸÄ±klÄ±k**: Sondan eklemeli yapÄ±sÄ± nedeniyle bir kelime kÃ¶kÃ¼nden teorik olarak sonsuz tÃ¼rev Ã¼retilebilmesi
2. **Leksikografik Belirsizlik**: AynÄ± yÃ¼zey formun farklÄ± baÄŸlamlarda farklÄ± kategorilere ait olabilmesi
3. **BaÄŸlamsal Anlam AyrÄ±mÄ±**: SÃ¶zdizimsel rolÃ¼n semantik iÃ§erikle iÃ§ iÃ§e geÃ§mesi
4. **Veri Sparsity**: TÃ¼rkÃ§e iÃ§in sÄ±nÄ±rlÄ± annotated corpus varlÄ±ÄŸÄ±
5. **Fonetik DeÄŸiÅŸimler**: Ses uyumu kurallarÄ±nÄ±n morfolojik analize etkileri

**Ã–nerilen Hibrit Ã‡Ã¶zÃ¼m Mimarisi:**

Sistemimiz, bu zorluklarÄ± aÅŸmak iÃ§in **Ã¼Ã§ katmanlÄ± hibrit mimari** kullanmaktadÄ±r:

```mermaid
graph TD
    A[Ham Metin] --> B[Ã–n Ä°ÅŸleme KatmanÄ±]
    B --> C[Morfolojik Analiz KatmanÄ±]
    C --> D[Ã–zellik Ã‡Ä±karma KatmanÄ±]
    D --> E[CRF SÄ±nÄ±flandÄ±rma KatmanÄ±]
    E --> F[Son Ä°ÅŸleme KatmanÄ±]
    F --> G[EtiketlenmiÅŸ Ã‡Ä±ktÄ±]
    
    B --> B1[Tokenizasyon]
    B --> B2[Normalizasyon]
    B --> B3[CÃ¼mle Segmentasyonu]
    
    C --> C1[KÃ¶k Ã‡Ä±karma]
    C --> C2[Morfem Segmentasyonu]
    C --> C3[Leksikon Arama]
    
    D --> D1[Morfolojik Ã–zellikler]
    D --> D2[BaÄŸlamsal Ã–zellikler]
    D --> D3[SÃ¶zdizimsel Ã–zellikler]
    
    E --> E1[Viterbi Ã‡Ã¶zÃ¼mleme]
    E --> E2[Belirsizlik YÃ¶netimi]
    
    F --> F1[Kural TabanlÄ± DÃ¼zeltme]
    F --> F2[TutarlÄ±lÄ±k KontrolÃ¼]
```

---

## AraÅŸtÄ±rma Motivasyonu ve Bilimsel KatkÄ±lar

### LiteratÃ¼r Analizi ve Mevcut Durum

TÃ¼rkÃ§e POS tagging alanÄ±nda yapÄ±lan Ã§alÄ±ÅŸmalar kronolojik olarak ÅŸu ÅŸekilde geliÅŸim gÃ¶stermiÅŸtir:

| DÃ¶nem | YaklaÅŸÄ±m | Temsili Ã‡alÄ±ÅŸmalar | DoÄŸruluk | Limitasyonlar |
|-------|----------|-------------------|----------|---------------|
| **1990-2000** | Kural TabanlÄ± | Oflazer (1994), Hakkani-TÃ¼r (2000) | ~85% | Manuel kural yazÄ±mÄ±, sÄ±nÄ±rlÄ± kapsam |
| **2000-2010** | Ä°statistiksel | Yuret & TÃ¼re (2006), EryiÄŸit (2007) | ~92% | Veri baÄŸÄ±mlÄ±lÄ±ÄŸÄ±, sparse data problemi |
| **2010-2015** | Makine Ã–ÄŸrenmesi | Sak et al. (2011), YÄ±ldÄ±z et al. (2012) | ~94% | Ã–zellik mÃ¼hendisliÄŸi yoÄŸunluÄŸu |
| **2015-2020** | Derin Ã–ÄŸrenme | Åeker & EryiÄŸit (2017), Kuru et al. (2020) | ~96% | YÃ¼ksek hesaplama maliyeti, veri aÃ§lÄ±ÄŸÄ± |
| **2020-2025** | Transformer | BERTurk, ConvBERT-TR | ~98% | Massive model boyutu, deployment zorluÄŸu |

### ğŸ”¬ Ã–zgÃ¼n Bilimsel KatkÄ±larÄ±mÄ±z

**1. Uyarlanabilir Morfolojik Segmentasyon AlgoritmasÄ±**

Geleneksel finite-state transducer yaklaÅŸÄ±mlarÄ±ndan farklÄ± olarak, **baÄŸlam-duyarlÄ± probabilistik segmentasyon** algoritmasÄ± geliÅŸtirdik:

```python
def adaptive_morphological_segmentation(word, context_window):
    """
    BaÄŸlam-duyarlÄ± morfolojik segmentasyon
    """
    # Viterbi tabanlÄ± dinamik programlama
    segmentation_lattice = build_lattice(word)
    context_features = extract_context_features(context_window)
    
    # BaÄŸlamsal aÄŸÄ±rlÄ±klandÄ±rma
    weighted_paths = apply_contextual_weights(segmentation_lattice, context_features)
    
    # Optimal segmentasyonu bul
    best_path = viterbi_decode(weighted_paths)
    return reconstruct_segmentation(best_path)
```

**2. Ã‡ok Ã–lÃ§ekli Ã–zellik FÃ¼zyonu (Multi-Scale Feature Fusion)**

FarklÄ± dilbilgisel seviyelerden Ã¶zellik Ã§Ä±karÄ±mÄ± ve fÃ¼zyonu:

- **Karakter-dÃ¼zeyi**: N-gram karakteristik Ã¶zellikler
- **Morfem-dÃ¼zeyi**: Ek kombinasyonlarÄ± ve kÃ¶k-ek iliÅŸkileri  
- **Kelime-dÃ¼zeyi**: Leksikografik ve semantik Ã¶zellikler
- **CÃ¼mle-dÃ¼zeyi**: SÃ¶zdizimsel baÄŸÄ±mlÄ±lÄ±klar ve konum bilgisi

**3. Belirsizlik-FarkÄ±nda Etiketleme (Uncertainty-Aware Tagging)**

Model gÃ¼venilirliÄŸini Ã¶lÃ§en ve belirsizlik durumlarÄ±nda alternatif hipotezler sunan sistem:

```python
class UncertaintyAwareTagger:
    def predict_with_confidence(self, sequence):
        predictions = self.crf_model.predict_proba(sequence)
        confidence_scores = self.calculate_confidence(predictions)
        
        # DÃ¼ÅŸÃ¼k gÃ¼venilirlik durumunda alternatif hipotezler
        uncertain_positions = confidence_scores < self.threshold
        alternative_hypotheses = self.generate_alternatives(
            sequence, uncertain_positions
        )
        
        return predictions, confidence_scores, alternative_hypotheses
```

**4. Dinamik Veri ArtÄ±rma Stratejileri**

TÃ¼rkÃ§e'nin morfolojik Ã¶zelliklerini kullanan veri artÄ±rma teknikleri:

- **Morfem PermÃ¼tasyonu**: Ek sÄ±ralamalarÄ±nÄ±n deÄŸiÅŸtirilmesi
- **Ses Uyumu VaryasyonlarÄ±**: Fonetik alternatiflerin Ã¼retilmesi
- **Leksikon GeniÅŸletme**: KÃ¶k-ek kombinasyonu ile yeni Ã¶rnekler
- **BaÄŸlamsal SubstitÃ¼syon**: Anlamsal olarak benzer kelimelerin deÄŸiÅŸtirilmesi

---

## Sistem Mimarisi ve Teknik Detaylar

### ModÃ¼ler TasarÄ±m Felsefesi

Sistemimiz, **SOLID prensiplerine** uygun, gevÅŸek baÄŸlÄ± (loosely coupled) ve yÃ¼ksek uyum (high cohesion) Ã¶zelliklerine sahip modÃ¼ler bir tasarÄ±mla geliÅŸtirilmiÅŸtir.

```
turkce-pos-tagger/
â”œâ”€â”€ ğŸ“ kod/
â”‚   â”œâ”€â”€ ğŸ§  core/                    # Ã‡ekirdek sistem bileÅŸenleri
â”‚   â”‚   â”œâ”€â”€ pipeline.py             # Ana iÅŸlem hattÄ± yÃ¶neticisi
â”‚   â”‚   â”œâ”€â”€ models/                 # ML model implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ crf_tagger.py       # CRF tabanlÄ± etiketleyici
â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_ensemble.py  # Hibrit ensemble model
â”‚   â”‚   â”‚   â””â”€â”€ uncertainty_model.py # Belirsizlik modelleme
â”‚   â”‚   â”œâ”€â”€ preprocessors/          # Ã–n iÅŸleme modÃ¼lleri
â”‚   â”‚   â”‚   â”œâ”€â”€ tokenizer.py        # TÃ¼rkÃ§e-Ã¶zel tokenizer
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py       # Metin normalizasyonu
â”‚   â”‚   â”‚   â””â”€â”€ sentence_splitter.py # CÃ¼mle segmentasyonu
â”‚   â”‚   â””â”€â”€ postprocessors/         # Son iÅŸleme modÃ¼lleri
â”‚   â”‚       â”œâ”€â”€ rule_applier.py     # Kural tabanlÄ± dÃ¼zeltmeler
â”‚   â”‚       â””â”€â”€ consistency_checker.py # TutarlÄ±lÄ±k kontrolÃ¼
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” features/                # Ã–zellik Ã§Ä±karma sistemleri
â”‚   â”‚   â”œâ”€â”€ morphological.py        # Morfolojik Ã¶zellik Ã§Ä±karÄ±cÄ±
â”‚   â”‚   â”œâ”€â”€ contextual.py           # BaÄŸlamsal Ã¶zellik Ã§Ä±karÄ±cÄ±
â”‚   â”‚   â”œâ”€â”€ syntactic.py            # SÃ¶zdizimsel Ã¶zellik Ã§Ä±karÄ±cÄ±
â”‚   â”‚   â””â”€â”€ fusion.py               # Ã‡ok Ã¶lÃ§ekli Ã¶zellik fÃ¼zyonu
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ augmentation/            # Veri artÄ±rma teknikleri
â”‚   â”‚   â”œâ”€â”€ morphological_aug.py    # Morfolojik veri artÄ±rma
â”‚   â”‚   â”œâ”€â”€ contextual_aug.py       # BaÄŸlamsal veri artÄ±rma
â”‚   â”‚   â””â”€â”€ synthetic_generator.py  # Sentetik veri Ã¼retimi
â”‚   â”‚
â”‚   â”œâ”€â”€ âš™ï¸ config/                  # YapÄ±landÄ±rma yÃ¶netimi
â”‚   â”‚   â”œâ”€â”€ model_config.py         # Model hiperparametreleri
â”‚   â”‚   â”œâ”€â”€ feature_config.py       # Ã–zellik yapÄ±landÄ±rmasÄ±
â”‚   â”‚   â””â”€â”€ pipeline_config.py      # Pipeline ayarlarÄ±
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š evaluation/              # DeÄŸerlendirme ve metrikler
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Performans metrikleri
â”‚   â”‚   â”œâ”€â”€ error_analysis.py       # Hata analizi araÃ§larÄ±
â”‚   â”‚   â””â”€â”€ benchmark.py            # KarÅŸÄ±laÅŸtÄ±rmalÄ± test
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils/                   # YardÄ±mcÄ± araÃ§lar
â”‚   â”‚   â”œâ”€â”€ data_loader.py          # Veri yÃ¼kleme utilities
â”‚   â”‚   â”œâ”€â”€ logger.py               # Loglama sistemi
â”‚   â”‚   â””â”€â”€ visualization.py        # GÃ¶rselleÅŸtirme araÃ§larÄ±
â”‚   â”‚
â”‚   â””â”€â”€ ğŸš€ main.py                  # Ana uygulama giriÅŸ noktasÄ±
â”‚
â”œâ”€â”€ ğŸ“Š data/                        # Veri setleri ve kaynaklar
â”‚   â”œâ”€â”€ raw/                        # Ham veri dosyalarÄ±
â”‚   â”œâ”€â”€ processed/                  # Ä°ÅŸlenmiÅŸ veri setleri
â”‚   â”œâ”€â”€ lexicons/                   # SÃ¶zlÃ¼kler ve morfolojik kaynaklar
â”‚   â”‚   â”œâ”€â”€ turkish_lexicon.json    # TÃ¼rkÃ§e kelime listesi
â”‚   â”‚   â”œâ”€â”€ morphological_rules.xml # Morfolojik kurallar
â”‚   â”‚   â””â”€â”€ pos_tagsets.yaml        # POS etiket setleri
â”‚   â””â”€â”€ models/                     # EÄŸitilmiÅŸ model dosyalarÄ±
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                   # AraÅŸtÄ±rma ve analiz notebook'larÄ±
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # Veri keÅŸfi ve analizi
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb # Ã–zellik mÃ¼hendisliÄŸi
â”‚   â”œâ”€â”€ 03_model_training.ipynb     # Model eÄŸitimi
â”‚   â”œâ”€â”€ 04_evaluation_analysis.ipynb # DeÄŸerlendirme analizi
â”‚   â””â”€â”€ 05_error_analysis.ipynb     # Hata analizi
â”‚
â”œâ”€â”€ ğŸ§ª tests/                       # Birim ve entegrasyon testleri
â”‚   â”œâ”€â”€ unit/                       # Birim testler
â”‚   â”œâ”€â”€ integration/                # Entegrasyon testleri
â”‚   â””â”€â”€ performance/                # Performans testleri
â”‚
â”œâ”€â”€ ğŸ“š docs/                        # DokÃ¼mantasyon
â”‚   â”œâ”€â”€ api/                        # API dokÃ¼mantasyonu
â”‚   â”œâ”€â”€ tutorials/                  # KullanÄ±m kÄ±lavuzlarÄ±
â”‚   â””â”€â”€ research/                   # AraÅŸtÄ±rma makaleleri
â”‚
â”œâ”€â”€ ğŸ³ docker/                      # Containerization
â”‚   â”œâ”€â”€ Dockerfile.dev              # Development environment
â”‚   â”œâ”€â”€ Dockerfile.prod             # Production environment
â”‚   â””â”€â”€ docker-compose.yml          # Multi-container setup
â”‚
â”œâ”€â”€ âš™ï¸ scripts/                     # Automation scripts
â”‚   â”œâ”€â”€ train.sh                    # Model eÄŸitim scripti
â”‚   â”œâ”€â”€ evaluate.sh                 # DeÄŸerlendirme scripti
â”‚   â””â”€â”€ deploy.sh                   # Deployment scripti
â”‚
â”œâ”€â”€ ğŸ“‹ requirements/                # Dependency management
â”‚   â”œâ”€â”€ base.txt                    # Temel baÄŸÄ±mlÄ±lÄ±klar
â”‚   â”œâ”€â”€ dev.txt                     # Development baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â””â”€â”€ prod.txt                    # Production baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚
â”œâ”€â”€ ğŸ”§ .github/                     # GitHub workflows
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                  # Continuous Integration
â”‚       â”œâ”€â”€ cd.yml                  # Continuous Deployment  
â”‚       â””â”€â”€ tests.yml               # Automated testing
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Proje dokÃ¼mantasyonu
â”œâ”€â”€ ğŸ“œ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ·ï¸ CHANGELOG.md                # SÃ¼rÃ¼m geÃ§miÅŸi
â”œâ”€â”€ ğŸ¤ CONTRIBUTING.md              # KatkÄ± rehberi
â”œâ”€â”€ ğŸ”’ SECURITY.md                  # GÃ¼venlik politikasÄ±
â””â”€â”€ âš™ï¸ pyproject.toml               # Modern Python packaging
```

### KatmanlÄ± Mimari DetaylarÄ±

**1. Veri EriÅŸim KatmanÄ± (Data Access Layer)**

```python
class DataAccessLayer:
    """
    Veri eriÅŸim katmanÄ± - Repository Pattern implementasyonu
    """
    def __init__(self, config: DataConfig):
        self.corpus_loader = CorpusLoader(config.corpus_path)
        self.lexicon_manager = LexiconManager(config.lexicon_path)
        self.cache_manager = CacheManager(config.cache_config)
    
    def load_training_data(self) -> TrainingDataset:
        """EÄŸitim verilerini yÃ¼kle"""
        return self.corpus_loader.load_annotated_corpus()
    
    def get_morphological_analysis(self, word: str) -> List[MorphAnalysis]:
        """Kelime iÃ§in morfolojik analiz getir"""
        return self.lexicon_manager.analyze_word(word)
```

**2. Ä°ÅŸ MantÄ±ÄŸÄ± KatmanÄ± (Business Logic Layer)**

```python
class POSTaggingService:
    """
    Ana iÅŸ mantÄ±ÄŸÄ± - POS tagging iÅŸlemlerini koordine eder
    """
    def __init__(self, model_manager: ModelManager, feature_extractor: FeatureExtractor):
        self.model_manager = model_manager
        self.feature_extractor = feature_extractor
        self.uncertainty_handler = UncertaintyHandler()
    
    def tag_sentence(self, sentence: str) -> TaggedSentence:
        """CÃ¼mle etiketleme ana metodu"""
        # 1. Ã–n iÅŸleme
        preprocessed = self.preprocess_sentence(sentence)
        
        # 2. Ã–zellik Ã§Ä±karma
        features = self.feature_extractor.extract_features(preprocessed)
        
        # 3. Model tahminleri
        predictions = self.model_manager.predict(features)
        
        # 4. Belirsizlik analizi
        confidence_scores = self.uncertainty_handler.calculate_confidence(predictions)
        
        # 5. Son iÅŸleme
        final_tags = self.postprocess_predictions(predictions, confidence_scores)
        
        return TaggedSentence(preprocessed.tokens, final_tags, confidence_scores)
```

**3. Sunum KatmanÄ± (Presentation Layer)**

```python
class POSTaggingAPI:
    """
    RESTful API interface
    """
    def __init__(self, pos_service: POSTaggingService):
        self.pos_service = pos_service
        self.rate_limiter = RateLimiter()
        self.request_validator = RequestValidator()
    
    @app.route('/api/v1/tag', methods=['POST'])
    @rate_limit(requests_per_minute=100)
    def tag_text(self):
        """Text etiketleme endpoint'i"""
        request_data = self.request_validator.validate(request.json)
        
        try:
            result = self.pos_service.tag_sentence(request_data['text'])
            return jsonify({
                'status': 'success',
                'tagged_sentence': result.to_conllu(),
                'confidence_scores': result.confidence_scores,
                'processing_time': result.processing_time
            })
        except Exception as e:
            return jsonify({
                'status': 'error',
                'error_message': str(e)
            }), 500
```

---

## Ä°novatif YaklaÅŸÄ±mlar ve Algoritmalar

### Hibrit Ensemble Modeli

Sistemimizin kalbi olan hibrit model, farklÄ± yaklaÅŸÄ±mlarÄ±n gÃ¼Ã§lÃ¼ yanlarÄ±nÄ± birleÅŸtiren **ensemble architecture** kullanmaktadÄ±r:

```python
class HybridEnsembleModel:
    """
    Ã‡oklu model yaklaÅŸÄ±mlarÄ±nÄ± birleÅŸtiren hibrit sistem
    """
    def __init__(self):
        # Temel modeller
        self.crf_model = CRFTagger()
        self.rule_based_model = RuleBasedTagger()
        self.neural_model = BiLSTMTagger()
        
        # Meta-Ã¶ÄŸrenme modeli
        self.meta_learner = MetaLearner()
        
        # Belirsizlik tahminleyicisi
        self.uncertainty_estimator = UncertaintyEstimator()
    
    def predict(self, features: FeatureVector) -> PredictionResult:
        """Hibrit ensemble prediction"""
        # Her modelden tahmin al
        crf_pred = self.crf_model.predict(features)
        rule_pred = self.rule_based_model.predict(features)
        neural_pred = self.neural_model.predict(features)
        
        # Model gÃ¼venilirlik skorlarÄ±
        crf_conf = self.uncertainty_estimator.estimate_confidence(crf_pred)
        rule_conf = self.uncertainty_estimator.estimate_confidence(rule_pred) 
        neural_conf = self.uncertainty_estimator.estimate_confidence(neural_pred)
        
        # Meta-Ã¶ÄŸrenme ile ensemble
        ensemble_input = EnsembleFeatures(
            predictions=[crf_pred, rule_pred, neural_pred],
            confidences=[crf_conf, rule_conf, neural_conf],
            context_features=features.contextual_features
        )
        
        final_prediction = self.meta_learner.combine_predictions(ensemble_input)
        
        return PredictionResult(
            tags=final_prediction.tags,
            confidence=final_prediction.confidence,
            individual_predictions={
                'crf': crf_pred,
                'rule_based': rule_pred, 
                'neural': neural_pred
            }
        )
```

### GeliÅŸmiÅŸ Ã–zellik MÃ¼hendisliÄŸi

**Morfolojik Ã–zellik Ã‡Ä±karÄ±cÄ±:**

```python
class MorphologicalFeatureExtractor:
    """
    TÃ¼rkÃ§e'ye Ã¶zel morfolojik Ã¶zellik Ã§Ä±karÄ±mÄ±
    """
    def __init__(self):
        self.morphological_analyzer = MorphologicalAnalyzer()
        self.phonetic_analyzer = PhoneticAnalyzer()
        self.vowel_harmony_checker = VowelHarmonyChecker()
    
    def extract_features(self, word: str, context: List[str]) -> MorphFeatures:
        """KapsamlÄ± morfolojik Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        features = MorphFeatures()
        
        # Temel morfolojik analiz
        morph_analysis = self.morphological_analyzer.analyze(word)
        features.root = morph_analysis.root
        features.suffixes = morph_analysis.suffixes
        features.pos_candidates = morph_analysis.pos_candidates
        
        # Fonetik Ã¶zellikler
        phonetic_features = self.phonetic_analyzer.analyze(word)
        features.vowel_harmony = self.vowel_harmony_checker.check(word)
        features.consonant_assimilation = phonetic_features.consonant_assimilation
        
        # Ä°statistiksel Ã¶zellikler
        features.suffix_frequency = self.calculate_suffix_frequency(morph_analysis.suffixes)
        features.morpheme_productivity = self.calculate_morpheme_productivity(morph_analysis)
        
        # BaÄŸlamsal morfolojik Ã¶zellikler
        features.context_morphological_compatibility = self.check_context_compatibility(
            morph_analysis, context
        )
        
        return features
```

**BaÄŸlamsal Ã–zellik Ã‡Ä±karÄ±cÄ±:**

```python
class ContextualFeatureExtractor:
    """
    Ã‡ok Ã¶lÃ§ekli baÄŸlamsal Ã¶zellik Ã§Ä±karÄ±mÄ±
    """
    def __init__(self, window_size: int = 5):
        self.window_size = window_size
        self.word_embeddings = WordEmbeddings()
        self.syntactic_parser = SyntacticParser()
    
    def extract_features(self, token_sequence: List[Token], position: int) -> ContextFeatures:
        """BaÄŸlamsal Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        features = ContextFeatures()
        
        # N-gram Ã¶zellikler
        features.left_context = self.extract_ngram_features(
            token_sequence, position, direction='left'
        )
        features.right_context = self.extract_ngram_features(
            token_sequence, position, direction='right'
        )
        
        # Semantik Ã¶zellikler
        features.semantic_similarity = self.calculate_semantic_similarity(
            token_sequence, position
        )
        
        # SÃ¶zdizimsel Ã¶zellikler
        syntactic_analysis = self.syntactic_parser.parse(token_sequence)
        features.dependency_relations = syntactic_analysis.get_dependencies(position)
        features.syntactic_role = syntactic_analysis.get_role(position)
        
        # Konum Ã¶zellikleri
        features.sentence_position = position / len(token_sequence)
        features.is_sentence_start = (position == 0)
        features.is_sentence_end = (position == len(token_sequence) - 1)
        
        return features
```

### Uyarlanabilir Ã–ÄŸrenme Stratejileri

**Aktif Ã–ÄŸrenme ile Model Ä°yileÅŸtirme:**

```python
class ActiveLearningFramework:
    """
    Belirsizlik tabanlÄ± aktif Ã¶ÄŸrenme sistemi
    """
    def __init__(self, base_model: HybridEnsembleModel):
        self.base_model = base_model
        self.uncertainty_sampler = UncertaintySampler()
        self.oracle_simulator = OracleSimulator()
    
    def iterative_improvement(self, unlabeled_data: Dataset) -> None:
        """Iteratif model iyileÅŸtirme"""
        for iteration in range(self.max_iterations):
            # En belirsiz Ã¶rnekleri seÃ§
            uncertain_samples = self.uncertainty_sampler.select_samples(
                unlabeled_data, 
                self.base_model,
                sample_size=100
            )
            
            # Oracle'dan etiketler al (simÃ¼lasyon)
            labeled_samples = self.oracle_simulator.label_samples(uncertain_samples)
            
            # Modeli yeniden eÄŸit
            self.base_model.incremental_train(labeled_samples)
            
            # Performans deÄŸerlendirmesi
            performance = self.evaluate_model()
            
            if performance.improvement < self.convergence_threshold:
                break
    
    def uncertainty_sampling_strategy(self, predictions: List[Prediction]) -> List[int]:
        """Belirsizlik tabanlÄ± Ã¶rnekleme stratej
