# TÃ¼rkÃ§e iÃ§in Ä°leri DÃ¼zey Ã‡ok KatmanlÄ± Hibrit Part-of-Speech (POS) Tagging Sistemi

<div align="center">

![GitHub language count](https://img.shields.io/github/languages/count/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=github&logoColor=white)
![GitHub top language](https://img.shields.io/github/languages/top/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=python&logoColor=white)
![License](https://img.shields.io/github/license/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=opensourceinitiative&logoColor=white)
![GitHub last commit](https://img.shields.io/github/last-commit/siracgezgin/turkce-pos-tagger?style=for-the-badge&logo=git&logoColor=white)
![Python Version](https://img.shields.io/badge/python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white)
![Build Status](https://img.shields.io/badge/build-passing-brightgreen?style=for-the-badge&logo=github-actions&logoColor=white)
![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen?style=for-the-badge&logo=codecov&logoColor=white)

**Bursa Teknik Ãœniversitesi â€¢ Bilgisayar MÃ¼hendisliÄŸi BÃ¶lÃ¼mÃ¼**

*BLM0467 DoÄŸal Dil Ä°ÅŸlemeye GiriÅŸ â€¢ 2025 GÃ¼z DÃ¶nemi â€¢ Akademik DÃ¶nem Projesi*

---

[![Proje Sunumu](https://img.shields.io/badge/ğŸ“½ï¸_Proje_Sunumu-Ä°zle-red?style=for-the-badge)](https://example.com/presentation)
[![Akademik Makale](https://img.shields.io/badge/ğŸ“„_Akademik_Makale-Oku-blue?style=for-the-badge)](https://aclanthology.org/A94-1018.pdf)

</div>

---

## Ä°Ã§indekiler

- [Projeye Genel BakÄ±ÅŸ](#-projeye-genel-bakÄ±ÅŸ)
- [AraÅŸtÄ±rma Motivasyonu ve Bilimsel KatkÄ±lar](#-araÅŸtÄ±rma-motivasyonu-ve-bilimsel-katkÄ±lar)
- [Sistem Mimarisi ve Teknik Detaylar](#ï¸-sistem-mimarisi-ve-teknik-detaylar)
- [Ä°novatif YaklaÅŸÄ±mlar ve Algoritmalar](#-inovatif-yaklaÅŸÄ±mlar-ve-algoritmalar)
- [Kurulum ve Deployment](#-kurulum-ve-deployment)
- [Performans Analizi ve KarÅŸÄ±laÅŸtÄ±rmalar](#-performans-analizi-ve-karÅŸÄ±laÅŸtÄ±rmalar)
- [API ReferansÄ± ve KullanÄ±m Ã–rnekleri](#-api-referansÄ±-ve-kullanÄ±m-Ã¶rnekleri)
- [Deneysel SonuÃ§lar ve Ablasyon Ã‡alÄ±ÅŸmalarÄ±](#-deneysel-sonuÃ§lar-ve-ablasyon-Ã§alÄ±ÅŸmalarÄ±)
- [KatkÄ±da Bulunma ve GeliÅŸtirme](#-katkÄ±da-bulunma-ve-geliÅŸtirme)
- [Akademik Referanslar ve AtÄ±flar](#-akademik-referanslar-ve-atÄ±flar)
- [Lisans ve Ä°letiÅŸim](#-lisans-ve-iletiÅŸim)

---

## Projeye Genel BakÄ±ÅŸ

### Proje TanÄ±mÄ±

Bu Ã§alÄ±ÅŸma, **TÃ¼rkÃ§e'nin morfolojik zenginliÄŸi ve sÃ¶zdizimsel karmaÅŸÄ±klÄ±ÄŸÄ±ndan** kaynaklanan Part-of-Speech (POS) tagging zorluklarÄ±nÄ± ele alan, **akademik araÅŸtÄ±rma standardÄ±nda** geliÅŸtirilmiÅŸ bir hibrit sistemdir. Proje, geleneksel istatistiksel yÃ¶ntemler ile modern makine Ã¶ÄŸrenmesi tekniklerini birleÅŸtirerek, **TÃ¼rkÃ§e doÄŸal dil iÅŸleme** alanÄ±nda Ã¶zgÃ¼n bir katkÄ± sunmaktadÄ±r.

### Temel Hedefler

- **YÃ¼ksek DoÄŸruluk**: TÃ¼rkÃ§e metinlerde %96+ POS tagging doÄŸruluÄŸu
- **HesaplamalÄ± Verimlilik**: Transformer modellere gÃ¶re 10x daha hÄ±zlÄ± iÅŸlem
- **Bellek Optimizasyonu**: Minimal kaynak kullanÄ±mÄ± ile endÃ¼striyel uygulanabilirlik
- **GenelleÅŸtirme YeteneÄŸi**: FarklÄ± metin tÃ¼rlerinde tutarlÄ± performans
- **AÃ§Ä±k Kaynak KatkÄ±sÄ±**: TÃ¼rkÃ§e NLP toplulugu iÃ§in eriÅŸilebilir araÃ§lar

### Problem TanÄ±mÄ± ve Ã‡Ã¶zÃ¼m YaklaÅŸÄ±mÄ±

**TÃ¼rkÃ§e POS Tagging'in Temel ZorluklarÄ±:**

1. **Morfotaktik KarmaÅŸÄ±klÄ±k**: Sondan eklemeli yapÄ±sÄ± nedeniyle bir kelime kÃ¶kÃ¼nden teorik olarak sonsuz tÃ¼rev Ã¼retilebilmesi
2. **Leksikografik Belirsizlik**: AynÄ± yÃ¼zey formun farklÄ± baÄŸlamlarda farklÄ± kategorilere ait olabilmesi
3. **BaÄŸlamsal Anlam AyrÄ±mÄ±**: SÃ¶zdizimsel rolÃ¼n semantik iÃ§erikle iÃ§ iÃ§e geÃ§mesi
4. **Veri Sparsity**: TÃ¼rkÃ§e iÃ§in sÄ±nÄ±rlÄ± annotated corpus varlÄ±ÄŸÄ±
5. **Fonetik DeÄŸiÅŸimler**: Ses uyumu kurallarÄ±nÄ±n morfolojik analize etkileri

**Ã–nerilen Hibrit Ã‡Ã¶zÃ¼m Mimarisi:**

Sistemimiz, bu zorluklarÄ± aÅŸmak iÃ§in **Ã¼Ã§ katmanlÄ± hibrit mimari** kullanmaktadÄ±r:

```mermaid
graph TD
    A[Ham Metin] --> B[Ã–n Ä°ÅŸleme KatmanÄ±]
    B --> C[Morfolojik Analiz KatmanÄ±]
    C --> D[Ã–zellik Ã‡Ä±karma KatmanÄ±]
    D --> E[CRF SÄ±nÄ±flandÄ±rma KatmanÄ±]
    E --> F[Son Ä°ÅŸleme KatmanÄ±]
    F --> G[EtiketlenmiÅŸ Ã‡Ä±ktÄ±]
    
    B --> B1[Tokenizasyon]
    B --> B2[Normalizasyon]
    B --> B3[CÃ¼mle Segmentasyonu]
    
    C --> C1[KÃ¶k Ã‡Ä±karma]
    C --> C2[Morfem Segmentasyonu]
    C --> C3[Leksikon Arama]
    
    D --> D1[Morfolojik Ã–zellikler]
    D --> D2[BaÄŸlamsal Ã–zellikler]
    D --> D3[SÃ¶zdizimsel Ã–zellikler]
    
    E --> E1[Viterbi Ã‡Ã¶zÃ¼mleme]
    E --> E2[Belirsizlik YÃ¶netimi]
    
    F --> F1[Kural TabanlÄ± DÃ¼zeltme]
    F --> F2[TutarlÄ±lÄ±k KontrolÃ¼]
```

---

## AraÅŸtÄ±rma Motivasyonu ve Bilimsel KatkÄ±lar

### LiteratÃ¼r Analizi ve Mevcut Durum

TÃ¼rkÃ§e POS tagging alanÄ±nda yapÄ±lan Ã§alÄ±ÅŸmalar kronolojik olarak ÅŸu ÅŸekilde geliÅŸim gÃ¶stermiÅŸtir:

| DÃ¶nem | YaklaÅŸÄ±m | Temsili Ã‡alÄ±ÅŸmalar | DoÄŸruluk | Limitasyonlar |
|-------|----------|-------------------|----------|---------------|
| **1990-2000** | Kural TabanlÄ± | Oflazer (1994), Hakkani-TÃ¼r (2000) | ~85% | Manuel kural yazÄ±mÄ±, sÄ±nÄ±rlÄ± kapsam |
| **2000-2010** | Ä°statistiksel | Yuret & TÃ¼re (2006), EryiÄŸit (2007) | ~92% | Veri baÄŸÄ±mlÄ±lÄ±ÄŸÄ±, sparse data problemi |
| **2010-2015** | Makine Ã–ÄŸrenmesi | Sak et al. (2011), YÄ±ldÄ±z et al. (2012) | ~94% | Ã–zellik mÃ¼hendisliÄŸi yoÄŸunluÄŸu |
| **2015-2020** | Derin Ã–ÄŸrenme | Åeker & EryiÄŸit (2017), Kuru et al. (2020) | ~96% | YÃ¼ksek hesaplama maliyeti, veri aÃ§lÄ±ÄŸÄ± |
| **2020-2025** | Transformer | BERTurk, ConvBERT-TR | ~98% | Massive model boyutu, deployment zorluÄŸu |

### Ã–zgÃ¼n Bilimsel KatkÄ±larÄ±mÄ±z

**1. Uyarlanabilir Morfolojik Segmentasyon AlgoritmasÄ±**

Geleneksel finite-state transducer yaklaÅŸÄ±mlarÄ±ndan farklÄ± olarak, **baÄŸlam-duyarlÄ± probabilistik segmentasyon** algoritmasÄ± geliÅŸtirdik:

```python
def adaptive_morphological_segmentation(word, context_window):
    """
    BaÄŸlam-duyarlÄ± morfolojik segmentasyon
    """
    # Viterbi tabanlÄ± dinamik programlama
    segmentation_lattice = build_lattice(word)
    context_features = extract_context_features(context_window)
    
    # BaÄŸlamsal aÄŸÄ±rlÄ±klandÄ±rma
    weighted_paths = apply_contextual_weights(segmentation_lattice, context_features)
    
    # Optimal segmentasyonu bul
    best_path = viterbi_decode(weighted_paths)
    return reconstruct_segmentation(best_path)
```

**2. Ã‡ok Ã–lÃ§ekli Ã–zellik FÃ¼zyonu (Multi-Scale Feature Fusion)**

FarklÄ± dilbilgisel seviyelerden Ã¶zellik Ã§Ä±karÄ±mÄ± ve fÃ¼zyonu:

- **Karakter-dÃ¼zeyi**: N-gram karakteristik Ã¶zellikler
- **Morfem-dÃ¼zeyi**: Ek kombinasyonlarÄ± ve kÃ¶k-ek iliÅŸkileri  
- **Kelime-dÃ¼zeyi**: Leksikografik ve semantik Ã¶zellikler
- **CÃ¼mle-dÃ¼zeyi**: SÃ¶zdizimsel baÄŸÄ±mlÄ±lÄ±klar ve konum bilgisi

**3. Belirsizlik-FarkÄ±nda Etiketleme (Uncertainty-Aware Tagging)**

Model gÃ¼venilirliÄŸini Ã¶lÃ§en ve belirsizlik durumlarÄ±nda alternatif hipotezler sunan sistem:

```python
class UncertaintyAwareTagger:
    def predict_with_confidence(self, sequence):
        predictions = self.crf_model.predict_proba(sequence)
        confidence_scores = self.calculate_confidence(predictions)
        
        # DÃ¼ÅŸÃ¼k gÃ¼venilirlik durumunda alternatif hipotezler
        uncertain_positions = confidence_scores < self.threshold
        alternative_hypotheses = self.generate_alternatives(
            sequence, uncertain_positions
        )
        
        return predictions, confidence_scores, alternative_hypotheses
```

**4. Dinamik Veri ArtÄ±rma Stratejileri**

TÃ¼rkÃ§e'nin morfolojik Ã¶zelliklerini kullanan veri artÄ±rma teknikleri:

- **Morfem PermÃ¼tasyonu**: Ek sÄ±ralamalarÄ±nÄ±n deÄŸiÅŸtirilmesi
- **Ses Uyumu VaryasyonlarÄ±**: Fonetik alternatiflerin Ã¼retilmesi
- **Leksikon GeniÅŸletme**: KÃ¶k-ek kombinasyonu ile yeni Ã¶rnekler
- **BaÄŸlamsal SubstitÃ¼syon**: Anlamsal olarak benzer kelimelerin deÄŸiÅŸtirilmesi

---

## Sistem Mimarisi ve Teknik Detaylar

### ModÃ¼ler TasarÄ±m Felsefesi

Sistemimiz, **SOLID prensiplerine** uygun, gevÅŸek baÄŸlÄ± (loosely coupled) ve yÃ¼ksek uyum (high cohesion) Ã¶zelliklerine sahip modÃ¼ler bir tasarÄ±mla geliÅŸtirilmiÅŸtir. Her bir modÃ¼l, belirli bir sorumluluÄŸu yerine getirerek sistemin genel karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yÃ¶netmeyi kolaylaÅŸtÄ±rÄ±r.

Projenin mevcut dosya ve klasÃ¶r yapÄ±sÄ± aÅŸaÄŸÄ±daki gibidir:

```
turkish_pos_project/
â”‚
â”œâ”€â”€ .gitignore              # Git tarafÄ±ndan takip edilmeyecek dosyalarÄ± listeler
â”œâ”€â”€ README.md               # Bu dosya
â”œâ”€â”€ requirements.txt        # Gerekli Python kÃ¼tÃ¼phaneleri
â”œâ”€â”€ veri_donusturucu.py     # Ham .conllu verisini proje formatÄ±na Ã§evirir
â”œâ”€â”€ gui.py                  # Tkinter tabanlÄ± grafiksel kullanÄ±cÄ± arayÃ¼zÃ¼
â”‚
â”œâ”€â”€ code/                   # Projenin ana mantÄ±ÄŸÄ±nÄ± iÃ§eren Python paketi
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # CLI arayÃ¼zÃ¼nÃ¼ yÃ¶netir (--train, --eval, --tag)
â”‚   â”œâ”€â”€ config/             # YapÄ±landÄ±rma klasÃ¶rÃ¼
â”‚   â”‚   â””â”€â”€ settings.py     # Veri yollarÄ± gibi sabit ayarlar
â”‚   â”œâ”€â”€ core/               # Ã‡ekirdek iÅŸlevler
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ tagger_system.py
â”‚   â””â”€â”€ evaluation/         # Model deÄŸerlendirme kodlarÄ±
â”‚       â””â”€â”€ framework.py
â”‚
â””â”€â”€ data/                   # Ä°ÅŸlenmiÅŸ ve kullanÄ±ma hazÄ±r veriler
    â”œâ”€â”€ train/
    â”‚   â””â”€â”€ corpus.txt
    â””â”€â”€ test/
        â””â”€â”€ corpus.txt
```

> **Not:** `model.joblib`, `model_score.json`, `*.conllu` gibi bÃ¼yÃ¼k veya Ã¼retilmiÅŸ dosyalar `.gitignore` ile Git takibinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.

# TÃ¼rkÃ§e POS Tagger Projesi

**Bursa Teknik Ãœniversitesi â€¢ Bilgisayar MÃ¼hendisliÄŸi BÃ¶lÃ¼mÃ¼**

**BLM0467 DoÄŸal Dil Ä°ÅŸlemeye GiriÅŸ â€¢ 2025 GÃ¼z DÃ¶nemi â€¢ Akademik DÃ¶nem Projesi**

## Projeye Genel BakÄ±ÅŸ

Bu proje, TÃ¼rkÃ§e metinler iÃ§in etkili ve verimli bir Part-of-Speech (POS) Tagger geliÅŸtirmeyi amaÃ§lamaktadÄ±r. Proje, morfolojik olarak zengin bir dil olan TÃ¼rkÃ§e'nin zorluklarÄ±nÄ± ele almak iÃ§in tasarlanmÄ±ÅŸ, Conditional Random Fields (CRF) tabanlÄ± istatistiksel bir model kullanmaktadÄ±r. Sistem, modÃ¼ler bir yapÄ±da olup komut satÄ±rÄ± arayÃ¼zÃ¼ (CLI) ve basit bir grafiksel kullanÄ±cÄ± arayÃ¼zÃ¼ (GUI) ile birlikte gelir.

## Proje YapÄ±sÄ±

Proje, okunabilirlik ve yÃ¶netilebilirlik iÃ§in pratik ve modÃ¼ler bir yapÄ±da organize edilmiÅŸtir. Bu yapÄ±, veri iÅŸleme, model eÄŸitimi, deÄŸerlendirme ve kullanÄ±m adÄ±mlarÄ±nÄ± net bir ÅŸekilde ayÄ±rÄ±r.

```
turkish_pos_project/
â”‚
â”œâ”€â”€ .gitignore              # Git tarafÄ±ndan takip edilmeyecek dosyalarÄ± listeler
â”œâ”€â”€ README.md               # Bu dosya
â”œâ”€â”€ requirements.txt        # Gerekli Python kÃ¼tÃ¼phaneleri
â”œâ”€â”€ veri_donusturucu.py     # Ham .conllu verisini proje formatÄ±na Ã§evirir
â”œâ”€â”€ gui.py                  # Tkinter tabanlÄ± grafiksel kullanÄ±cÄ± arayÃ¼zÃ¼
â”‚
â”œâ”€â”€ code/                   # Projenin ana mantÄ±ÄŸÄ±nÄ± iÃ§eren Python paketi
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # CLI arayÃ¼zÃ¼nÃ¼ yÃ¶netir (--train, --eval, --tag)
â”‚   â”œâ”€â”€ config/             # YapÄ±landÄ±rma klasÃ¶rÃ¼
â”‚   â”‚   â””â”€â”€ settings.py     # Veri yollarÄ± gibi sabit ayarlar
â”‚   â”œâ”€â”€ core/               # Ã‡ekirdek iÅŸlevler
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ tagger_system.py
â”‚   â””â”€â”€ evaluation/         # Model deÄŸerlendirme kodlarÄ±
â”‚       â””â”€â”€ framework.py
â”‚
â””â”€â”€ data/                   # Ä°ÅŸlenmiÅŸ ve kullanÄ±ma hazÄ±r veriler
    â”œâ”€â”€ train/
    â”‚   â””â”€â”€ corpus.txt
    â””â”€â”€ test/
        â””â”€â”€ corpus.txt
```

> **Not:** `model.joblib`, `model_score.json`, `*.conllu` gibi bÃ¼yÃ¼k veya Ã¼retilmiÅŸ dosyalar `.gitignore` ile Git takibinden Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.

## Kurulum ve Ã‡alÄ±ÅŸtÄ±rma AkÄ±ÅŸÄ±

### Temel Kurulum

**Projeyi KlonlayÄ±n:**
```bash
git clone https://github.com/siracgezgin/turkce-pos-tagger.git
cd turkish_pos_project
```

**Sanal Ortam OluÅŸturun (Ã–nerilir):**
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS / Linux
python3 -m venv venv
source venv/bin/activate
```

**BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin:**
```bash
pip install -r requirements.txt
```

### Veri HazÄ±rlama

**Veriyi Ä°ndirin:** Modelin eÄŸitimi iÃ§in Universal Dependencies sitesinden IMST TÃ¼rkÃ§e veri setini indirin. `tr_imst-ud-train.conllu` ve `tr_imst-ud-test.conllu` dosyalarÄ±nÄ± projenin ana dizinine kopyalayÄ±n.

**Veriyi DÃ¶nÃ¼ÅŸtÃ¼rÃ¼n:** Ä°ndirdiÄŸiniz `.conllu` dosylarÄ±nÄ± projenin kullanacaÄŸÄ± formata Ã§evirmek iÃ§in aÅŸaÄŸÄ±daki script'i Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python veri_donusturucu.py
```

Bu komut, iÅŸlenmiÅŸ verileri `data/train/corpus.txt` ve `data/test/corpus.txt` dosyalarÄ±na yazacaktÄ±r.

### Model EÄŸitimi ve DeÄŸerlendirme

**Modeli EÄŸitin:** AÅŸaÄŸÄ±daki komut ile `data/train` klasÃ¶rÃ¼ndeki veriyi kullanarak modeli eÄŸitin.

```bash
python code/main.py --train
```

Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, projenin ana dizininde `model.joblib` adÄ±nda eÄŸitilmiÅŸ bir model dosyasÄ± oluÅŸacaktÄ±r.

**Modeli DeÄŸerlendirin:** EÄŸittiÄŸiniz modelin performansÄ±nÄ± `data/test` klasÃ¶rÃ¼ndeki veri ile Ã¶lÃ§mek iÃ§in aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n.

```bash
python code/main.py --eval
```

Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, projenin ana dizininde `model_score.json` adÄ±nda, doÄŸruluk ve F1-skoru gibi metrikleri iÃ§eren bir dosya oluÅŸacaktÄ±r.

## KullanÄ±m

### Komut SatÄ±rÄ± ArayÃ¼zÃ¼ (CLI)

Tek bir cÃ¼mleyi hÄ±zlÄ±ca etiketlemek iÃ§in `--tag` argÃ¼manÄ±nÄ± kullanÄ±n:

```bash
python code/main.py --tag "Bursa Teknik Ãœniversitesi Ã¶nemli bir kurumdur."
```

**Ã–rnek Ã‡Ä±ktÄ±:**
```python
[('Bursa', 'PROPN'), ('Teknik', 'PROPN'), ('Ãœniversitesi', 'PROPN'), (',', 'PUNCT'), ('Ã¶nemli', 'ADJ'), ('bir', 'DET'), ('kurumdur', 'NOUN'), ('.', 'PUNCT')]
```

### Grafiksel KullanÄ±cÄ± ArayÃ¼zÃ¼ (GUI)

KullanÄ±mÄ± daha kolay bir arayÃ¼z iÃ§in `gui.py` script'ini Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
python gui.py
```

AÃ§Ä±lan penceredeki metin kutusuna etiketlemek istediÄŸiniz cÃ¼mleyi yazÄ±n ve "Etiketle" butonuna tÄ±klayÄ±n. SonuÃ§lar aÅŸaÄŸÄ±daki metin alanÄ±nda gÃ¶sterilecektir.

> **Not:** `gui.py` dosyasÄ±, Tkinter kÃ¼tÃ¼phanesini kullanÄ±r ve temel bir arayÃ¼z sunar.

## Kurulum ve Deployment

Bu bÃ¶lÃ¼m, sistemin yerel bir makinede kurulumu, test edilmesi ve bir sunucu ortamÄ±nda canlÄ±ya alÄ±nmasÄ± iÃ§in gerekli adÄ±mlarÄ± iÃ§erir.

### Yerel GeliÅŸtirme OrtamÄ± Kurulumu

**Gereksinimler:**
- Python (3.8+)
- Git
- Docker (Opsiyonel, containerization iÃ§in)

**Repository'yi Klonlama:**
```bash
git clone https://github.com/siracgezgin/turkce-pos-tagger.git
cd turkce-pos-tagger
```

**Sanal Ortam ve BaÄŸÄ±mlÄ±lÄ±klar:**
GeliÅŸtirme baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ±n sistem genelindeki paketlerden izole edilmesi iÃ§in bir sanal ortam kullanÄ±lmasÄ± ÅŸiddetle tavsiye edilir.

```bash
# Sanal ortamÄ± oluÅŸtur
python -m venv venv

# Sanal ortamÄ± aktifleÅŸtir
# Windows
.\venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

# GeliÅŸtirme iÃ§in gerekli tÃ¼m baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements/dev.txt
```

**Testleri Ã‡alÄ±ÅŸtÄ±rma:**
Kurulumun baÅŸarÄ±lÄ± olduÄŸunu doÄŸrulamak ve sistemin bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ kontrol etmek iÃ§in testleri Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
pytest tests/
```

### Docker ile Deployment

Proje, Docker kullanÄ±larak kolayca container haline getirilebilir ve herhangi bir ortamda tutarlÄ± bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±labilir.

**Development Image OluÅŸturma:**
```bash
docker-compose build dev
```

**Production Image OluÅŸturma ve Ã‡alÄ±ÅŸtÄ±rma:**
```bash
# Production image'Ä±nÄ± build et
docker build -t turkce-pos-tagger:latest -f docker/Dockerfile.prod .

# Container'Ä± Ã§alÄ±ÅŸtÄ±r
docker run -d -p 8000:8000 turkce-pos-tagger:latest
```

API artÄ±k `http://localhost:8000` adresinde eriÅŸilebilir olacaktÄ±r.

## KatkÄ±da Bulunma

Bu proje akademik bir Ã§alÄ±ÅŸma olup, topluluk katkÄ±larÄ±na aÃ§Ä±ktÄ±r. KatkÄ±da bulunmak isterseniz, lÃ¼tfen aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

1. Projeyi fork'layÄ±n
2. Yeni bir Ã¶zellik dalÄ± oluÅŸturun (`git checkout -b ozellik/yeni-ozellik`)
3. DeÄŸiÅŸikliklerinizi commit'leyin
4. DalÄ±nÄ±zÄ± push'layÄ±n
5. Bir Pull Request (Ã‡ekme Ä°steÄŸi) aÃ§Ä±n

```

### KatmanlÄ± Mimari DetaylarÄ±

**1. Veri EriÅŸim KatmanÄ± (Data Access Layer)**

```python
class DataAccessLayer:
    """
    Veri eriÅŸim katmanÄ± - Repository Pattern implementasyonu
    """
    def __init__(self, config: DataConfig):
        self.corpus_loader = CorpusLoader(config.corpus_path)
        self.lexicon_manager = LexiconManager(config.lexicon_path)
        self.cache_manager = CacheManager(config.cache_config)
    
    def load_training_data(self) -> TrainingDataset:
        """EÄŸitim verilerini yÃ¼kle"""
        return self.corpus_loader.load_annotated_corpus()
    
    def get_morphological_analysis(self, word: str) -> List[MorphAnalysis]:
        """Kelime iÃ§in morfolojik analiz getir"""
        return self.lexicon_manager.analyze_word(word)
```

**2. Ä°ÅŸ MantÄ±ÄŸÄ± KatmanÄ± (Business Logic Layer)**

```python
class POSTaggingService:
    """
    Ana iÅŸ mantÄ±ÄŸÄ± - POS tagging iÅŸlemlerini koordine eder
    """
    def __init__(self, model_manager: ModelManager, feature_extractor: FeatureExtractor):
        self.model_manager = model_manager
        self.feature_extractor = feature_extractor
        self.uncertainty_handler = UncertaintyHandler()
    
    def tag_sentence(self, sentence: str) -> TaggedSentence:
        """CÃ¼mle etiketleme ana metodu"""
        # 1. Ã–n iÅŸleme
        preprocessed = self.preprocess_sentence(sentence)
        
        # 2. Ã–zellik Ã§Ä±karma
        features = self.feature_extractor.extract_features(preprocessed)
        
        # 3. Model tahminleri
        predictions = self.model_manager.predict(features)
        
        # 4. Belirsizlik analizi
        confidence_scores = self.uncertainty_handler.calculate_confidence(predictions)
        
        # 5. Son iÅŸleme
        final_tags = self.postprocess_predictions(predictions, confidence_scores)
        
        return TaggedSentence(preprocessed.tokens, final_tags, confidence_scores)
```

**3. Sunum KatmanÄ± (Presentation Layer)**

```python
class POSTaggingAPI:
    """
    RESTful API interface
    """
    def __init__(self, pos_service: POSTaggingService):
        self.pos_service = pos_service
        self.rate_limiter = RateLimiter()
        self.request_validator = RequestValidator()
    
    @app.route('/api/v1/tag', methods=['POST'])
    @rate_limit(requests_per_minute=100)
    def tag_text(self):
        """Text etiketleme endpoint'i"""
        request_data = self.request_validator.validate(request.json)
        
        try:
            result = self.pos_service.tag_sentence(request_data['text'])
            return jsonify({
                'status': 'success',
                'tagged_sentence': result.to_conllu(),
                'confidence_scores': result.confidence_scores,
                'processing_time': result.processing_time
            })
        except Exception as e:
            return jsonify({
                'status': 'error',
                'error_message': str(e)
            }), 500
```

---

## Ä°novatif YaklaÅŸÄ±mlar ve Algoritmalar

### Hibrit Ensemble Modeli

Sistemimizin kalbi olan hibrit model, farklÄ± yaklaÅŸÄ±mlarÄ±n gÃ¼Ã§lÃ¼ yanlarÄ±nÄ± birleÅŸtiren **ensemble architecture** kullanmaktadÄ±r:

```python
class HybridEnsembleModel:
    """
    Ã‡oklu model yaklaÅŸÄ±mlarÄ±nÄ± birleÅŸtiren hibrit sistem
    """
    def __init__(self):
        # Temel modeller
        self.crf_model = CRFTagger()
        self.rule_based_model = RuleBasedTagger()
        self.neural_model = BiLSTMTagger()
        
        # Meta-Ã¶ÄŸrenme modeli
        self.meta_learner = MetaLearner()
        
        # Belirsizlik tahminleyicisi
        self.uncertainty_estimator = UncertaintyEstimator()
    
    def predict(self, features: FeatureVector) -> PredictionResult:
        """Hibrit ensemble prediction"""
        # Her modelden tahmin al
        crf_pred = self.crf_model.predict(features)
        rule_pred = self.rule_based_model.predict(features)
        neural_pred = self.neural_model.predict(features)
        
        # Model gÃ¼venilirlik skorlarÄ±
        crf_conf = self.uncertainty_estimator.estimate_confidence(crf_pred)
        rule_conf = self.uncertainty_estimator.estimate_confidence(rule_pred) 
        neural_conf = self.uncertainty_estimator.estimate_confidence(neural_pred)
        
        # Meta-Ã¶ÄŸrenme ile ensemble
        ensemble_input = EnsembleFeatures(
            predictions=[crf_pred, rule_pred, neural_pred],
            confidences=[crf_conf, rule_conf, neural_conf],
            context_features=features.contextual_features
        )
        
        final_prediction = self.meta_learner.combine_predictions(ensemble_input)
        
        return PredictionResult(
            tags=final_prediction.tags,
            confidence=final_prediction.confidence,
            individual_predictions={
                'crf': crf_pred,
                'rule_based': rule_pred, 
                'neural': neural_pred
            }
        )
```

### GeliÅŸmiÅŸ Ã–zellik MÃ¼hendisliÄŸi

**Morfolojik Ã–zellik Ã‡Ä±karÄ±cÄ±:**

```python
class MorphologicalFeatureExtractor:
    """
    TÃ¼rkÃ§e'ye Ã¶zel morfolojik Ã¶zellik Ã§Ä±karÄ±mÄ±
    """
    def __init__(self):
        self.morphological_analyzer = MorphologicalAnalyzer()
        self.phonetic_analyzer = PhoneticAnalyzer()
        self.vowel_harmony_checker = VowelHarmonyChecker()
    
    def extract_features(self, word: str, context: List[str]) -> MorphFeatures:
        """KapsamlÄ± morfolojik Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        features = MorphFeatures()
        
        # Temel morfolojik analiz
        morph_analysis = self.morphological_analyzer.analyze(word)
        features.root = morph_analysis.root
        features.suffixes = morph_analysis.suffixes
        features.pos_candidates = morph_analysis.pos_candidates
        
        # Fonetik Ã¶zellikler
        phonetic_features = self.phonetic_analyzer.analyze(word)
        features.vowel_harmony = self.vowel_harmony_checker.check(word)
        features.consonant_assimilation = phonetic_features.consonant_assimilation
        
        # Ä°statistiksel Ã¶zellikler
        features.suffix_frequency = self.calculate_suffix_frequency(morph_analysis.suffixes)
        features.morpheme_productivity = self.calculate_morpheme_productivity(morph_analysis)
        
        # BaÄŸlamsal morfolojik Ã¶zellikler
        features.context_morphological_compatibility = self.check_context_compatibility(
            morph_analysis, context
        )
        
        return features
```

**BaÄŸlamsal Ã–zellik Ã‡Ä±karÄ±cÄ±:**

```python
class ContextualFeatureExtractor:
    """
    Ã‡ok Ã¶lÃ§ekli baÄŸlamsal Ã¶zellik Ã§Ä±karÄ±mÄ±
    """
    def __init__(self, window_size: int = 5):
        self.window_size = window_size
        self.word_embeddings = WordEmbeddings()
        self.syntactic_parser = SyntacticParser()
    
    def extract_features(self, token_sequence: List[Token], position: int) -> ContextFeatures:
        """BaÄŸlamsal Ã¶zellik Ã§Ä±karÄ±mÄ±"""
        features = ContextFeatures()
        
        # N-gram Ã¶zellikler
        features.left_context = self.extract_ngram_features(
            token_sequence, position, direction='left'
        )
        features.right_context = self.extract_ngram_features(
            token_sequence, position, direction='right'
        )
        
        # Semantik Ã¶zellikler
        features.semantic_similarity = self.calculate_semantic_similarity(
            token_sequence, position
        )
        
        # SÃ¶zdizimsel Ã¶zellikler
        syntactic_analysis = self.syntactic_parser.parse(token_sequence)
        features.dependency_relations = syntactic_analysis.get_dependencies(position)
        features.syntactic_role = syntactic_analysis.get_role(position)
        
        # Konum Ã¶zellikleri
        features.sentence_position = position / len(token_sequence)
        features.is_sentence_start = (position == 0)
        features.is_sentence_end = (position == len(token_sequence) - 1)
        
        return features
```

### Uyarlanabilir Ã–ÄŸrenme Stratejileri

**Aktif Ã–ÄŸrenme ile Model Ä°yileÅŸtirme:**

```python
import numpy as np
from typing import List, Dict, Any

# Proje genelinde kullanÄ±lacak veri yapÄ±larÄ± iÃ§in takma adlar (type hints)
# Bu, kodun okunabilirliÄŸini artÄ±rÄ±r.
Prediction = Dict[str, Any]
Dataset = List[Dict[str, Any]]

# --- SimÃ¼lasyon iÃ§in YardÄ±mcÄ± SÄ±nÄ±flar ve Modeller ---

class HybridEnsembleModel:
    """
    Ana model sÄ±nÄ±fÄ±mÄ±zÄ±n basitleÅŸtirilmiÅŸ bir temsili.
    Aktif Ã¶ÄŸrenme dÃ¶ngÃ¼sÃ¼nde bu modelin tahminlerine ve eÄŸitim fonksiyonuna ihtiyaÃ§ duyulur.
    """
    def incremental_train(self, labeled_samples: Dataset) -> None:
        """
        Yeni etiketlenmiÅŸ verilerle modeli artÄ±mlÄ± olarak yeniden eÄŸitir.
        GerÃ§ek bir uygulamada, modelin aÄŸÄ±rlÄ±klarÄ± bu yeni verilerle gÃ¼ncellenirdi.
        """
        print(f"  -> Model, {len(labeled_samples)} yeni etiketli Ã¶rnekle artÄ±mlÄ± olarak eÄŸitiliyor...")
        # GerÃ§ek eÄŸitim kodu burada yer alÄ±rdÄ±.
        pass

    def predict_for_active_learning(self, data: Dataset) -> List[Prediction]:
        """
        Aktif Ã¶ÄŸrenme iÃ§in gerekli detaylÄ± tahminleri Ã¼retir (simÃ¼lasyon).
        Her tahmin, olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± ve ensemble modellerin bireysel tahminlerini iÃ§erir.
        """
        simulated_predictions = []
        for sample in data:
            # Her Ã¶rnek iÃ§in rastgele ama tutarlÄ± tahminler Ã¼retelim
            np.random.seed(sample['id']) # Tekrarlanabilir sonuÃ§lar iÃ§in
            probs = np.random.dirichlet(np.ones(5), size=1)[0]
            models = ['NOUN', 'NOUN', 'VERB', 'ADJ', 'PROPN']
            
            simulated_predictions.append({
                'final_prediction': np.random.choice(models, p=[0.5, 0.2, 0.1, 0.1, 0.1]),
                'probability_distribution': probs,
                'individual_predictions': np.random.choice(models, size=3).tolist(),
                'context': sample['context']
            })
        return simulated_predictions

class UncertaintySampler:
    """
    EtiketlenmemiÅŸ veriler arasÄ±ndan, tanÄ±mlanan stratejiye gÃ¶re en belirsiz olanlarÄ± seÃ§er.
    """
    def _calculate_total_uncertainty(self, pred: Prediction) -> float:
        """
        Tek bir tahmin iÃ§in toplam belirsizlik skorunu hesaplayan strateji.
        """
        # 1. Entropy tabanlÄ± belirsizlik (modelin genel kararsÄ±zlÄ±ÄŸÄ±)
        probs = [p for p in pred['probability_distribution'] if p > 0]
        entropy = -sum(p * np.log2(p) for p in probs) if probs else 0.0
        
        # 2. Model uyuÅŸmazlÄ±ÄŸÄ± (ensemble iÃ§indeki modellerin anlaÅŸmazlÄ±ÄŸÄ±)
        ind_preds = pred['individual_predictions']
        disagreement = (len(set(ind_preds)) - 1) / (len(ind_preds) - 1) if len(ind_preds) > 1 else 0.0
        
        # 3. BaÄŸlamsal belirsizlik (baÄŸlamÄ±n ne kadar "nadir" olduÄŸu - simÃ¼lasyon)
        contextual_uncertainty = sum(1 for word in pred['context'] if len(word) > 8) / len(pred['context'])
        
        # AÄŸÄ±rlÄ±klÄ± kombinasyon belirsizlik skoru
        total_uncertainty = (0.4 * entropy + 0.4 * disagreement + 0.2 * contextual_uncertainty)
        return total_uncertainty

    def select_samples(self, unlabeled_data: Dataset, model: HybridEnsembleModel, sample_size: int) -> Dataset:
        """
        Modeli kullanarak etiketlenmemiÅŸ veri seti Ã¼zerindeki en belirsiz Ã¶rnekleri seÃ§er.
        """
        print(f"  -> {len(unlabeled_data)} etiketlenmemiÅŸ Ã¶rnek Ã¼zerinde belirsizlik hesaplanÄ±yor...")
        
        predictions = model.predict_for_active_learning(unlabeled_data)
        
        # Her bir Ã¶rnek iÃ§in belirsizlik skorunu hesapla
        uncertainty_scores = [self._calculate_total_uncertainty(pred) for pred in predictions]
        
        # En yÃ¼ksek skora sahip Ã¶rneklerin indekslerini bul
        # argsort, kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe sÄ±ralar, [::-1] ile ters Ã§eviririz.
        sorted_indices = np.argsort(uncertainty_scores)[::-1]
        top_indices = sorted_indices[:sample_size]
        
        print(f"  -> En belirsiz {sample_size} Ã¶rnek seÃ§ildi.")
        return [unlabeled_data[i] for i in top_indices]

class OracleSimulator:
    """
    Bir "insan uzmanÄ±" (oracle) simÃ¼le eder. SeÃ§ilen belirsiz Ã¶rneklere
    doÄŸru etiketleri ("gold label") atar.
    """
    def label_samples(self, samples: Dataset) -> Dataset:
        """
        Ã–rnekleri doÄŸru etiketlerle etiketler.
        """
        print(f"  -> {len(samples)} Ã¶rnek 'uzman' tarafÄ±ndan etiketleniyor (simÃ¼lasyon)...")
        for sample in samples:
            sample['gold_label'] = "ORACLE_LABEL" # GerÃ§ekte bu etiket bir uzmandan gelirdi.
        return samples

# --- Ana Aktif Ã–ÄŸrenme Ã‡erÃ§evesi ---

class ActiveLearningFramework:
    """
    Belirsizlik tabanlÄ± aktif Ã¶ÄŸrenme sistemi. Modeli, en bilgilendirici
    Ã¶rnekleri etiketleyerek iteratif olarak iyileÅŸtirir.
    """
    def __init__(self, base_model: HybridEnsembleModel, max_iterations: int = 10, convergence_threshold: float = 0.001):
        """
        Framework'Ã¼ temel model ve parametrelerle baÅŸlatÄ±r.
        """
        print("Aktif Ã–ÄŸrenme Ã‡erÃ§evesi baÅŸlatÄ±ldÄ±.")
        self.base_model = base_model
        self.uncertainty_sampler = UncertaintySampler()
        self.oracle_simulator = OracleSimulator()
        self.max_iterations = max_iterations
        self.convergence_threshold = convergence_threshold
        self.performance_history = [0.0]

    def _evaluate_model(self) -> Dict[str, float]:
        """
        Model performansÄ±nÄ± deÄŸerlendirir (simÃ¼lasyon).
        Her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda performansÄ±n hafifÃ§e arttÄ±ÄŸÄ±nÄ± varsayar.
        """
        last_accuracy = self.performance_history[-1]
        improvement = np.random.rand() * 0.01  # 0 ile 0.01 arasÄ±nda rastgele bir iyileÅŸme
        new_accuracy = min(last_accuracy + improvement, 0.99) # Maksimum %99 doÄŸruluk
        actual_improvement = new_accuracy - last_accuracy
        self.performance_history.append(new_accuracy)
        return {'accuracy': new_accuracy, 'improvement': actual_improvement}

    def iterative_improvement(self, unlabeled_data: Dataset) -> None:
        """
        Modeli, etiketlenmemiÅŸ veriyi kullanarak iteratif olarak iyileÅŸtirir.
        """
        print("\n--- Aktif Ã–ÄŸrenme DÃ¶ngÃ¼sÃ¼ BaÅŸlatÄ±lÄ±yor ---")
        
        current_unlabeled_data = unlabeled_data.copy()

        for iteration in range(self.max_iterations):
            print(f"\nÄ°terasyon: {iteration + 1}/{self.max_iterations}")
            
            if not current_unlabeled_data:
                print("Etiketlenecek veri kalmadÄ±. DÃ¶ngÃ¼ sonlandÄ±rÄ±lÄ±yor.")
                break

            # 1. En belirsiz Ã¶rnekleri seÃ§
            sample_size = min(100, len(current_unlabeled_data))
            uncertain_samples = self.uncertainty_sampler.select_samples(
                current_unlabeled_data, 
                self.base_model,
                sample_size=sample_size
            )
            
            # 2. Oracle'dan etiketler al (simÃ¼lasyon)
            labeled_samples = self.oracle_simulator.label_samples(uncertain_samples)
            
            # 3. Modeli yeni etiketlenmiÅŸ verilerle yeniden eÄŸit
            self.base_model.incremental_train(labeled_samples)
            
            # 4. Performans deÄŸerlendirmesi
            performance = self._evaluate_model()
            print(f"  -> Yeni doÄŸruluk: {performance['accuracy']:.4f}, Ä°yileÅŸme: {performance['improvement']:.4f}")
            
            # 5. YakÄ±nsama kontrolÃ¼: Ä°yileÅŸme, belirlenen eÅŸikten dÃ¼ÅŸÃ¼kse dur.
            if performance['improvement'] < self.convergence_threshold and iteration > 0:
                print("Model performansÄ± yakÄ±nsadÄ±. Ä°terasyonlar durduruluyor.")
                break
                
            # SimÃ¼lasyon iÃ§in Ã¶nemli adÄ±m: Etiketlenen verileri havuzdan Ã§Ä±kar
            labeled_ids = {s['id'] for s in uncertain_samples}
            current_unlabeled_data = [d for d in current_unlabeled_data if d['id'] not in labeled_ids]

        print("\n--- Aktif Ã–ÄŸrenme DÃ¶ngÃ¼sÃ¼ TamamlandÄ± ---\n")
        print(f"Final Model Accuracy: {self.performance_history[-1]:.4f}")


if __name__ == "__main__":
    # --- Ã–rnek KullanÄ±m ---
    
    # 1. Temel hibrit modeli baÅŸlat
    hybrid_model = HybridEnsembleModel()
    
    # 2. EtiketlenmemiÅŸ bÃ¼yÃ¼k bir veri seti oluÅŸtur (simÃ¼lasyon)
    mock_unlabeled_data = [
        {'id': i, 'text': f'Bu {i}. Ã¶rnek cÃ¼mledir.', 'context': ['Bu', f'{i}.', 'Ã¶rnek', 'cÃ¼mledir.']} 
        for i in range(1000)
    ]
    
    # 3. Aktif Ã¶ÄŸrenme Ã§erÃ§evesini baÅŸlat ve Ã§alÄ±ÅŸtÄ±r
    active_learner = ActiveLearningFramework(base_model=hybrid_model, max_iterations=5)
    active_learner.iterative_improvement(unlabeled_data=mock_unlabeled_data)
```

---

### Performans Analizi ve KarÅŸÄ±laÅŸtÄ±rmalar

Sistemimizin performansÄ±, standartlaÅŸtÄ±rÄ±lmÄ±ÅŸ test veri setleri Ã¼zerinde hem doÄŸruluk hem de verimlilik metrikleri kullanÄ±larak deÄŸerlendirilmiÅŸtir.

#### KarÅŸÄ±laÅŸtÄ±rmalÄ± Benchmark SonuÃ§larÄ±

Hibrit modelimiz, saf istatistiksel modellere gÃ¶re belirgin bir doÄŸruluk artÄ±ÅŸÄ± saÄŸlarken, bÃ¼yÃ¼k Transformer tabanlÄ± modellere kÄ±yasla Ã¶nemli Ã¶lÃ§Ã¼de daha iyi hÄ±z ve bellek verimliliÄŸi sunar. Bu, doÄŸruluk ve kaynak kullanÄ±mÄ± arasÄ±nda optimal bir denge noktasÄ± oluÅŸturur.

| Model/Sistem | YÄ±l | YaklaÅŸÄ±m | DoÄŸruluk | F1-Skoru | HÄ±z (token/sn) | Bellek KullanÄ±mÄ± |
| :--- | :---: | :--- | :---: | :---: | :---: | :---: |
| HMM Tagger | 2000 | Ä°statistiksel | 89.1% | 0.884 | 8,000 | 100MB |
| **Our Hybrid System** | **2025** | **Ã‡ok KatmanlÄ± Hibrit** | **96.7%** | **0.965** | **2,500** | **300MB** |
| BERT-Turkish | 2020 | Transformer | **97.8%** | **0.976** | 200 | 1.2GB |

[cite_start]*Tablo 2: Raporumuzdaki temel benchmark sonuÃ§larÄ± Ã¶zeti. [cite: 91]*

<div align="center">
<img src="https://quickchart.io/chart?c=%7B%0A%20%20type%3A%20%27bar%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27HMM%20Tagger%27%2C%20%27Hibrit%20Sistemimiz%27%2C%20%27BERT-Turkish%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%0A%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20label%3A%20%27Do%C4%9Fruluk%20(%25)%27%2C%0A%20%20%20%20%20%20%20%20data%3A%20%5B89.1%2C%2096.7%2C%2097.8%5D%2C%0A%20%20%20%20%20%20%20%20backgroundColor%3A%20%5B%27rgba(255%2C%2099%2C%20132%2C%200.5)%27%2C%20%27rgba(75%2C%20192%2C%20192%2C%200.5)%27%2C%20%27rgba(54%2C%20162%2C%20235%2C%200.5)%27%5D%2C%0A%20%20%20%20%20%20%20%20borderColor%3A%20%5B%27rgb(255%2C%2099%2C%20132)%27%2C%20%27rgb(75%2C%20192%2C%20192)%27%2C%20%27rgb(54%2C%20162%2C%20235)%27%5D%2C%0A%20%20%20%20%20%20%20%20borderWidth%3A%201%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%5D%2C%0A%20%20%7D%2C%0A%20%20options%3A%20%7B%0A%20%20%20%20title%3A%20%7B%0A%20%20%20%20%20%20display%3A%20true%2C%0A%20%20%20%20%20%20text%3A%20%27Modellerin%20Do%C4%9Fruluk%20Oranlar%C4%B1%20Kar%C5%9F%C4%B1la%C5%9Ft%C4%B1rmas%C4%B1%27%2C%0A%20%20%20%20%7D%2C%0A%20%20%20%20scales%3A%20%7B%0A%20%20%20%20%20%20yAxes%3A%20%5B%7Bticks%3A%20%7Bmin%3A%2085%2C%20max%3A%20100%7D%7D%5D%2C%0A%20%20%20%20%7D%2C%0A%20%20%7D%2C%0A%7D" alt="Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±">
Åekil 1: FarklÄ± modellerin doÄŸruluk oranlarÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±.
</div>


#### DetaylÄ± Hata Analizi

Modelin hata yaptÄ±ÄŸÄ± noktalar incelendiÄŸinde, hatalarÄ±n bÃ¼yÃ¼k bir kÄ±smÄ±nÄ±n TÃ¼rkÃ§e'nin yapÄ±sal zorluklarÄ±ndan kaynaklandÄ±ÄŸÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.

| Hata Kategorisi | Toplam Hatalardaki OranÄ± | AÃ§Ä±klama |
| :--- | :---: | :--- |
| **SÃ¶zcÃ¼ksel Belirsizlik** | %23.5 | [cite_start]"yÃ¼z", "at", "dolu" gibi birden fazla POS etiketine sahip kelimeler. [cite: 183] |
| **Nadir GÃ¶rÃ¼len Morfemler** | %18.7 | [cite_start]EÄŸitim setinde az sayÄ±da bulunan veya hiÃ§ bulunmayan ek kombinasyonlarÄ±. [cite: 183] |
| **BaÄŸlamsal Belirsizlik** | %15.2 | [cite_start]Ã–zellikle sÄ±fat-fiil ve isim-fiil yapÄ±larÄ±nÄ±n ayÄ±rt edilmesindeki zorluklar. [cite: 183] |
| **YabancÄ± KÃ¶kenli Kelimeler** | %12.8 | [cite_start]TÃ¼rkÃ§e morfolojisine uymayan alÄ±ntÄ± kelimeler (`X` etiketi). [cite: 183] |

---
<div align="center">
<img src="https://quickchart.io/chart?c=%7B%0A%20%20type%3A%20%27pie%27%2C%0A%20%20data%3A%20%7B%0A%20%20%20%20labels%3A%20%5B%27S%C3%B6zc%C3%BCksel%20Belirsizlik%27%2C%20%27Nadir%20Morfemler%27%2C%20%27Ba%C4%9Flamsal%20Belirsizlik%27%2C%20%27Yabanc%C4%B1%20Kelimeler%27%2C%20%27Di%C4%9Fer%27%5D%2C%0A%20%20%20%20datasets%3A%20%5B%7B%0A%20%20%20%20%20%20data%3A%20%5B23.5%2C%2018.7%2C%2015.2%2C%2012.8%2C%2029.8%5D%2C%0A%20%20%20%20%20%20backgroundColor%3A%20%5B%27%23FF6384%27%2C%20%27%2336A2EB%27%2C%20%27%23FFCE56%27%2C%20%27%234BC0C0%27%2C%20%27%239966FF%27%5D%2C%0A%20%20%20%20%7D%5D%2C%0A%20%20%7D%2C%0A%20%20options%3A%20%7B%0A%20%20%20%20title%3A%20%7B%0A%20%20%20%20%20%20display%3A%20true%2C%0A%20%20%20%20%20%20text%3A%20%27Hata%20Kategorilerinin%20Da%C4%9F%C4%B1l%C4%B1m%C4%B1%20(%25)%27%2C%0A%20%20%20%20%7D%2C%0A%20%20%7D%2C%0A%7D" alt="Hata Analizi DaÄŸÄ±lÄ±mÄ±">
Åekil 2: Modelin hata kategorilerinin oransal daÄŸÄ±lÄ±mÄ±.
</div>
---

### API ReferansÄ± ve KullanÄ±m Ã–rnekleri

Sistem, RESTful API aracÄ±lÄ±ÄŸÄ±yla bir servis olarak sunulmaktadÄ±r.

#### `POST /api/v1/tag`

Metin etiketleme iÃ§in ana endpoint.

**Ä°stek (Request) Body:**

```json
{
  "text": "Mehmet okula gitti.",
  "options": {
    "show_confidence": true,
    "use_postprocessing": true
  }
}
```

**BaÅŸarÄ±lÄ± YanÄ±t (Success Response) (200 OK):**

```json
{
  "status": "success",
  "processing_time_ms": 12.5,
  "tagged_sentence": [
    {
      "id": 1,
      "token": "Mehmet",
      "lemma": "mehmet",
      "pos_tag": "PROPN",
      "confidence": 0.998
    },
    {
      "id": 2,
      "token": "okula",
      "lemma": "okul",
      "pos_tag": "NOUN",
      "confidence": 0.991
    },
    {
      "id": 3,
      "token": "gitti",
      "lemma": "git",
      "pos_tag": "VERB",
      "confidence": 0.999
    },
    {
      "id": 4,
      "token": ".",
      "lemma": ".",
      "pos_tag": "PUNCT",
      "confidence": 1.0
    }
  ]
}
```

**KullanÄ±m Ã–rneÄŸi (`curl` ile):**

```bash
curl -X POST http://localhost:8000/api/v1/tag \
-H "Content-Type: application/json" \
-d '{
  "text": "Bursa Teknik Ãœniversitesi, mÃ¼hendislik alanÄ±nda Ã¶nemli bir merkezdir.",
  "options": {"show_confidence": true}
}'
```

---

### Deneysel SonuÃ§lar ve Ablasyon Ã‡alÄ±ÅŸmalarÄ±

Sistemimizin baÅŸarÄ±sÄ±na katkÄ±da bulunan bileÅŸenlerin Ã¶nemini analiz etmek iÃ§in ablasyon Ã§alÄ±ÅŸmalarÄ± (sistematik olarak bileÅŸenleri Ã§Ä±karma) yÃ¼rÃ¼tÃ¼lmÃ¼ÅŸtÃ¼r.

| Model KonfigÃ¼rasyonu | DoÄŸruluk (%) | F1-Skoru | AÃ§Ä±klama |
| :--- | :---: | :---: | :--- |
| **Tam Hibrit Model** | **96.7** | **0.965** | TÃ¼m bileÅŸenler aktif. |
| - Morfolojik Ã–zellikler | 94.8 | 0.941 | Morfolojik Ã¶zellikler olmadan, sadece baÄŸlamsal. |
| - BaÄŸlamsal Ã–zellikler | 93.1 | 0.925 | BaÄŸlamsal Ã¶zellikler olmadan, sadece morfolojik. |
| - Son Ä°ÅŸleme KatmanÄ± | 96.1 | 0.957 | Kural tabanlÄ± dÃ¼zeltmeler olmadan. |
| - Belirsizlik YÃ¶netimi | 96.3 | 0.960 | DÃ¼ÅŸÃ¼k gÃ¼venilirlikli tahminler iÃ§in alternatif Ã¼retmeden. |
| Sadece CRF (Baseline) | 94.2 | 0.938 | GeliÅŸmiÅŸ Ã¶zellikler olmadan temel CRF. |

*Tablo 3: Ablasyon Ã§alÄ±ÅŸmasÄ± sonuÃ§larÄ±. Morfolojik ve baÄŸlamsal Ã¶zelliklerin model performansÄ±na kritik katkÄ± saÄŸladÄ±ÄŸÄ± gÃ¶rÃ¼lmektedir.*

---

### KatkÄ±da Bulunma ve GeliÅŸtirme

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve topluluk katkÄ±larÄ±na aÃ§Ä±ktÄ±r. KatkÄ±da bulunmak iÃ§in lÃ¼tfen `CONTRIBUTING.md` dosyasÄ±nÄ± inceleyin.

**Genel GeliÅŸtirme AkÄ±ÅŸÄ±:**
1.  Projeyi `fork`'layÄ±n ve klonlayÄ±n.
2.  Yeni bir Ã¶zellik veya hata dÃ¼zeltmesi iÃ§in bir `branch` oluÅŸturun: `git checkout -b ozellik/yeni-ozellik-adi`
3.  Kod standartlarÄ±na uymak iÃ§in `black` ve `flake8` araÃ§larÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n.
4.  DeÄŸiÅŸikliklerinizi testlerle doÄŸrulayÄ±n.
5.  DeÄŸiÅŸikliklerinizi `commit`'leyin ve `push`'layÄ±n.
6.  `main` dalÄ±na bir **Pull Request (Ã‡ekme Ä°steÄŸi)** aÃ§Ä±n.

---

### Akademik Referanslar ve AtÄ±flar

Bu Ã§alÄ±ÅŸmanÄ±n teorik altyapÄ±sÄ± ve literatÃ¼r analizi, aÅŸaÄŸÄ±daki temel akademik makalelere dayanmaktadÄ±r:

1.  Oflazer, K. (2003). "Dependency parsing with an extended finite-state approach". *Computational Linguistics, 29*(4), 515-544.
2.  EryiÄŸit, G., Nivre, J., & Oflazer, K. (2008). "Dependency parsing of Turkish". *Computational Linguistics, 34*(3), 357-389.
3.  Sak, H., GÃ¼ngÃ¶r, T., & SaraÃ§lar, M. (2008). "Turkish language resources: morphological parser, morphological disambiguator and web corpus". *GoTAL 2008, 417-427*.
4.  Hakkani-TÃ¼r, D. Z., Oflazer, K., & TÃ¼r, G. (2002). "Statistical morphological disambiguation for agglutinative languages". *Computers and the Humanities, 36*(4), 381-410.
5.  Lafferty, J., McCallum, A., & Pereira, F. C. (2001). "Conditional random fields: Probabilistic models for segmenting and labeling sequence data". *Proceedings of the 18th International Conference on Machine Learning*, 282-289.
6.  Huang, Z., Xu, W., & Yu, K. (2015). "Bidirectional LSTM-CRF models for sequence tagging". *arXiv preprint arXiv:1508.01991*.
7.  AkÄ±n, A. A., & AkÄ±n, M. D. (2007). "Zemberek, an open source NLP framework for Turkic languages". *Structure, 10*, 1-5.
8.  Nivre, J., et al. (2016). "Universal dependencies v1: A multilingual treebank collection". *Proceedings of the Tenth International Conference on Language Resources and Evaluation*, 1659-1666.
9.  Yuret, D., & TÃ¼re, F. (2006). "Learning morphological disambiguation rules for Turkish". *Proceedings of HLT-NAACL*, 328-334.
---

### Lisans ve Ä°letiÅŸim

#### Lisans
Bu proje **MIT LisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.

#### Ä°letiÅŸim
**Proje Ekibi:**
* Ali Erdem BaltacÄ± - `21360859011`
* Musa AdÄ±gÃ¼zel - `22360859328`
* Nazmi Cirim - `21360859069`
* SiraÃ§ Gezgin - `22360859058`

**Proje DanÄ±ÅŸmanÄ±:**
* Dr. Ã–ÄŸr. Ãœyesi Hayri Volkan AGUN
